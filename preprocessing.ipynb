{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163ad997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ecgdetectors import Detectors\n",
    "# import tensorflow as tf\n",
    "# from tcn import TCN\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29269fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max (x, x_min, x_max):\n",
    "    return (x - x_min) / (x_max - x_min)\n",
    "\n",
    "def load_ecg(file_path, t_path):\n",
    "    ecg = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            ecg.append([x for x in line.split()])\n",
    "\n",
    "    ecg_2 = np.asarray([np.float32(x[2]) for x in ecg[1:]], dtype=np.float32)\n",
    "    t_marks = np.loadtxt(t_path, dtype=int)\n",
    "    t_indexes = np.arange(2, len(t_marks)+2, 3)\n",
    "    t_marks = t_marks[t_indexes]\n",
    "    labels = np.zeros(len(ecg_2), dtype=int)\n",
    "    # fill labels with 1s +- 3 samples around each T mark\n",
    "    for t in t_marks:\n",
    "        labels[max(0, t-3):min(len(labels), t+4)] = 1\n",
    "    ecg_2 = ecg_2[:t_marks[-1] + 21]\n",
    "    limit = len(ecg_2) - len(ecg_2) % 2048\n",
    "    ecg_2 = ecg_2[:limit]\n",
    "    labels = labels[:limit]\n",
    "    ecg_2 = ecg_2.reshape(len(ecg_2)//2048, 2048)\n",
    "    labels = labels.reshape(len(labels)//2048, 2048)\n",
    "    return ecg_2, t_marks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "581da766",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_bruno, t_bruno, labels_bruno = load_ecg('/home/david/Documents/ECG_delineation/ecg-sanos/wetransfer_ecgs_2024-09-09_1340/377-Bruno/Estudio.vak', 'Serie_Bruno.txt')\n",
    "ecg_mario, t_mario, labels_mario = load_ecg('/home/david/Documents/ECG_delineation/ecg-sanos/wetransfer_ecgs_2024-09-09_1340/ecg-mario/Estudio.vak', 'Serie_Mario.txt')\n",
    "ecg_leo, t_leo, labels_leo = load_ecg('/home/david/Documents/ECG_delineation/ecg-sanos/wetransfer_ecgs_2024-09-09_1340/390-Leopoldo-Diagno/Estudio.vak', 'Serie_Leo.txt')\n",
    "ecg_julia, t_julia, labels_julia = load_ecg('/home/david/Documents/ECG_delineation/ecg-sanos/wetransfer_ecgs_2024-09-09_1340/ecg-julia/Estudio.vak', 'Serie_Julia.txt')\n",
    "ecg_seba, t_seba, labels_seba = load_ecg('/home/david/Documents/ECG_delineation/ecg-sanos/wetransfer_ecgs_2024-09-09_1340/368Seba-Diagno/Estudio.vak', 'Serie_Seba_corte_1.txt')\n",
    "\n",
    "ecg = np.concatenate((ecg_bruno, ecg_mario, ecg_leo, ecg_julia, ecg_seba), axis=0)\n",
    "labels = np.concatenate((labels_bruno, labels_mario, labels_leo, labels_julia, labels_seba), axis=0)\n",
    "# shuffle ecg and labels in unison\n",
    "p = np.random.permutation(len(ecg))\n",
    "ecg = ecg[p]\n",
    "ecg = min_max(ecg, np.min(ecg), np.max(ecg))\n",
    "labels = labels[p]\n",
    "\n",
    "ecg_train = ecg[:int(0.75*ecg.shape[0])]\n",
    "labels_train = labels[:int(0.75*labels.shape[0])]\n",
    "ecg_val = ecg[int(0.75*ecg.shape[0]):int(0.9*ecg.shape[0])]\n",
    "labels_val = labels[int(0.75*labels.shape[0]):int(0.9*labels.shape[0])]\n",
    "ecg_test = ecg[int(0.9*ecg.shape[0]):]\n",
    "labels_test = labels[int(0.9*labels.shape[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ec6ba48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2422556)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_count = np.sum(labels_train)\n",
    "labels_train.shape[0]*labels_train.shape[1] - pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b6f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- datos ya cargados: ecg_2 (1D float32), labels (0/1 int) ---\n",
    "pos_count = np.sum(labels_train)\n",
    "neg_count = labels_train.shape[0]*labels_train.shape[1] - pos_count\n",
    "print(\"pos_count:\", pos_count, \"neg_count:\", neg_count, \"ratio neg/pos:\", (neg_count/ (pos_count+1e-9)))\n",
    "\n",
    "# 1) Construir sample_weight por timestep:\n",
    "# warmup_mask = 0 para primeros RF timesteps (como ya hacías)\n",
    "kernel_size = 3\n",
    "dilations = [1,2,4,8,16,32]\n",
    "nb_stacks = 1\n",
    "RF = 1 + 2 * (kernel_size - 1) * np.sum(dilations) * nb_stacks\n",
    "warmup = int(RF) - 1\n",
    "warmup_mask = np.ones(warmup, dtype='float32')\n",
    "\n",
    "# class weighting: dar mayor peso a los positivos.\n",
    "# típico: pos_weight = neg_count/pos_count (clamp para evitar valores enormes)\n",
    "pos_weight = float(min(50.0, (neg_count / max(1, pos_count))))\n",
    "class_weights_per_timestep = np.where(labels_train==1, pos_weight, 1.0).astype('float32')\n",
    "\n",
    "sample_weight_seq = warmup_mask * class_weights_per_timestep\n",
    "\n",
    "# 2) Crear dataset por ventanas (recomendado):\n",
    "window_size = 2048   # >= RF, ajusta si memoria lo permite\n",
    "stride = 1024        # overlap\n",
    "X_windows = []\n",
    "SW_windows = []\n",
    "for start in range(0, T-window_size+1, stride):\n",
    "    end = start + window_size\n",
    "    X_windows.append(ecg_2[start:end].reshape(window_size,1))\n",
    "    Y_windows.append(labels[start:end].reshape(window_size,1))\n",
    "    SW_windows.append(sample_weight_seq[start:end])\n",
    "# include final tail\n",
    "if (T - window_size) % stride != 0 and T > window_size:\n",
    "    start = T - window_size\n",
    "    X_windows.append(ecg_2[start:start+window_size].reshape(window_size,1))\n",
    "    Y_windows.append(labels[start:start+window_size].reshape(window_size,1))\n",
    "    SW_windows.append(sample_weight_seq[start:start+window_size])\n",
    "\n",
    "X_windows = np.stack(X_windows).astype('float32')  # (n_windows, window_size, 1)\n",
    "Y_windows = np.stack(Y_windows).astype('float32')\n",
    "SW_windows = np.stack(SW_windows).astype('float32')\n",
    "\n",
    "print(\"n_windows:\", X_windows.shape[0], \"window_size:\", window_size)\n",
    "\n",
    "# 3) tf.data dataset\n",
    "batch_size = 8\n",
    "ds = tf.data.Dataset.from_tensor_slices((X_windows, Y_windows, SW_windows))\n",
    "ds = ds.shuffle(200).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# 4) modelo (usar logits o sigmoid, aquí mantengo sigmoid y sample_weight)\n",
    "inp = tf.keras.Input(shape=(None, 1))\n",
    "x = TCN(\n",
    "    nb_filters=32,\n",
    "    kernel_size=kernel_size,\n",
    "    dilations=dilations,\n",
    "    nb_stacks=nb_stacks,\n",
    "    padding='causal',\n",
    "    dropout_rate=0.1,\n",
    "    return_sequences=True,\n",
    "    use_skip_connections=True\n",
    ")(inp)\n",
    "out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inp, out)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)  # LR más conservador\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.AUC(name='auc'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall')])\n",
    "\n",
    "# callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=6, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "# 5) Entrenar\n",
    "history = model.fit(ds, epochs=30, callbacks=callbacks, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
