{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "163ad997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ecgdetectors import Detectors\n",
    "# import tensorflow as tf\n",
    "# from tcn import TCN\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29269fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max (x, x_min, x_max):\n",
    "    return (x - x_min) / (x_max - x_min)\n",
    "\n",
    "def load_ecg(file_path, t_path):\n",
    "    ecg = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            ecg.append([x for x in line.split()])\n",
    "\n",
    "    ecg_2 = np.asarray([np.float32(x[2]) for x in ecg[1:]], dtype=np.float32)\n",
    "    t_marks = np.loadtxt(t_path, dtype=int)\n",
    "    t_indexes = np.arange(2, len(t_marks)+2, 3)\n",
    "    t_marks = t_marks[t_indexes]\n",
    "    labels = np.zeros(len(ecg_2), dtype=int)\n",
    "    # fill labels with 1s +- 3 samples around each T mark\n",
    "    for t in t_marks:\n",
    "        labels[max(0, t-3):min(len(labels), t+4)] = 1\n",
    "    ecg_2 = ecg_2[:t_marks[-1] + 21]\n",
    "    limit = len(ecg_2) - len(ecg_2) % 2048\n",
    "    ecg_2 = ecg_2[:limit]\n",
    "    labels = labels[:limit]\n",
    "    ecg_2 = ecg_2.reshape(len(ecg_2)//2048, 2048)\n",
    "    labels = labels.reshape(len(labels)//2048, 2048)\n",
    "    return ecg_2, t_marks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "581da766",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_bruno, t_bruno, labels_bruno = load_ecg('/home/david/Documents/ECG_delineation/ecg-sanos/wetransfer_ecgs_2024-09-09_1340/377-Bruno/Estudio.vak', 'Serie_Bruno.txt')\n",
    "ecg_mario, t_mario, labels_mario = load_ecg('/home/david/Documents/ECG_delineation/ecg-sanos/wetransfer_ecgs_2024-09-09_1340/ecg-mario/Estudio.vak', 'Serie_Mario.txt')\n",
    "ecg_leo, t_leo, labels_leo = load_ecg('/home/david/Documents/ECG_delineation/ecg-sanos/wetransfer_ecgs_2024-09-09_1340/390-Leopoldo-Diagno/Estudio.vak', 'Serie_Leo.txt')\n",
    "ecg_julia, t_julia, labels_julia = load_ecg('/home/david/Documents/ECG_delineation/ecg-sanos/wetransfer_ecgs_2024-09-09_1340/ecg-julia/Estudio.vak', 'Serie_Julia.txt')\n",
    "ecg_seba, t_seba, labels_seba = load_ecg('/home/david/Documents/ECG_delineation/ecg-sanos/wetransfer_ecgs_2024-09-09_1340/368Seba-Diagno/Estudio.vak', 'Serie_Seba_corte_1.txt')\n",
    "\n",
    "ecg = np.concatenate((ecg_bruno, ecg_mario, ecg_leo, ecg_julia, ecg_seba), axis=0)\n",
    "labels = np.concatenate((labels_bruno, labels_mario, labels_leo, labels_julia, labels_seba), axis=0)\n",
    "# shuffle ecg and labels in unison\n",
    "p = np.random.permutation(len(ecg))\n",
    "ecg = ecg[p]\n",
    "ecg = min_max(ecg, np.min(ecg), np.max(ecg))\n",
    "labels = labels[p]\n",
    "\n",
    "ecg_train = ecg[:int(0.75*ecg.shape[0])]\n",
    "labels_train = labels[:int(0.75*labels.shape[0])]\n",
    "ecg_val = ecg[int(0.75*ecg.shape[0]):int(0.9*ecg.shape[0])]\n",
    "labels_val = labels[int(0.75*labels.shape[0]):int(0.9*labels.shape[0])]\n",
    "ecg_test = ecg[int(0.9*ecg.shape[0]):]\n",
    "labels_test = labels[int(0.9*labels.shape[0]):]\n",
    "\n",
    "# save each pair in the same npz non compressed file\n",
    "np.savez('ecg_data_train.npz', ecg=ecg_train, labels=labels_train)\n",
    "np.savez('ecg_data_val.npz', ecg=ecg_val, labels=labels_val)\n",
    "np.savez('ecg_data_test.npz', ecg=ecg_test, labels=labels_test)\n",
    "\n",
    "# load example\n",
    "# data = np.load('ecg_data_train.npz')\n",
    "# ecg_train = data['ecg']\n",
    "# labels_train = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b6f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- datos ya cargados: ecg_2 (1D float32), labels (0/1 int) ---\n",
    "pos_count = np.sum(labels_train)\n",
    "neg_count = labels_train.shape[0]*labels_train.shape[1] - pos_count\n",
    "print(\"pos_count:\", pos_count, \"neg_count:\", neg_count, \"ratio neg/pos:\", (neg_count/ (pos_count+1e-9)))\n",
    "\n",
    "# 1) Construir sample_weight por timestep:\n",
    "# warmup_mask = 0 para primeros RF timesteps (como ya hacías)\n",
    "kernel_size = 3\n",
    "dilations = [1,2,4,8,16,32]\n",
    "nb_stacks = 1\n",
    "RF = 1 + 2 * (kernel_size - 1) * np.sum(dilations) * nb_stacks\n",
    "warmup = int(RF) - 1\n",
    "warmup_mask = np.ones(warmup, dtype='float32')\n",
    "\n",
    "# class weighting: dar mayor peso a los positivos.\n",
    "# típico: pos_weight = neg_count/pos_count (clamp para evitar valores enormes)\n",
    "pos_weight = float(min(50.0, (neg_count / max(1, pos_count))))\n",
    "class_weights_per_timestep = np.where(labels_train==1, pos_weight, 1.0).astype('float32')\n",
    "\n",
    "# use per-timestep class weights and apply warmup (zero out first `warmup` timesteps)\n",
    "sample_weight_seq = class_weights_per_timestep.copy().astype('float32')  # shape (n_samples, seq_len)\n",
    "\n",
    "if warmup > 0:\n",
    "    if warmup < sample_weight_seq.shape[1]:\n",
    "        sample_weight_seq[:, :warmup] = 0.0\n",
    "    else:\n",
    "        # if warmup >= seq_len, zero all weights to be safe\n",
    "        sample_weight_seq[:] = 0.0\n",
    "\n",
    "# use ecg_train / labels_train directly (add channel dim)\n",
    "ecg_train = ecg_train.reshape((-1, ecg_train.shape[1], 1)).astype('float32')\n",
    "labels_train = labels_train.reshape((-1, labels_train.shape[1], 1)).astype('float32')\n",
    "sample_weight_seq = sample_weight_seq.reshape((-1, sample_weight_seq.shape[1], 1)).astype('float32')\n",
    "\n",
    "print(\"Using ecg_train shape:\", ecg_train.shape, \"labels shape:\", labels_train.shape, \"sample_weight shape:\", sample_weight_seq.shape)\n",
    "\n",
    "# tf.data dataset\n",
    "batch_size = 8\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((ecg_train, labels_train, sample_weight_seq))\n",
    "ds_train = ds_train.shuffle(200).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ecg_val = ecg_val.reshape((-1, ecg_val.shape[1], 1)).astype('float32')\n",
    "labels_val = labels_val.reshape((-1, labels_val.shape[1], 1)).astype('float32')\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((ecg_val, labels_val))\n",
    "ds_val = ds_val.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# 4) modelo (usar logits o sigmoid, aquí mantengo sigmoid y sample_weight)\n",
    "inp = tf.keras.Input(shape=(None, 1))\n",
    "x = TCN(\n",
    "    nb_filters=32,\n",
    "    kernel_size=kernel_size,\n",
    "    dilations=dilations,\n",
    "    nb_stacks=nb_stacks,\n",
    "    padding='causal',\n",
    "    dropout_rate=0.1,\n",
    "    return_sequences=True,\n",
    "    use_skip_connections=True\n",
    ")(inp)\n",
    "out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inp, out)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)  # LR más conservador\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.AUC(name='auc'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall')])\n",
    "\n",
    "# callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=6, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "# 5) Entrenar\n",
    "history = model.fit(train=ds_train, validation=ds_val, epochs=30, callbacks=callbacks, verbose=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
